{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, SGD\n# print(os.listdir(\"/kaggle/input/flowers-recognition/flowers\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-19T13:32:34.60997Z","iopub.execute_input":"2022-11-19T13:32:34.610637Z","iopub.status.idle":"2022-11-19T13:32:40.350586Z","shell.execute_reply.started":"2022-11-19T13:32:34.610535Z","shell.execute_reply":"2022-11-19T13:32:40.349616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define parameters\nCLASS_NUM = 5\nBATCH_SIZE = 16\nEPOCH_STEPS = int(4323/BATCH_SIZE)\nIMAGE_SHAPE = (224, 224, 3)\nIMAGE_TRAIN = '/kaggle/input/flowers-recognition/flowers'\nMODEL_NAME = 'googlenet_flower.h5'","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:40.352606Z","iopub.execute_input":"2022-11-19T13:32:40.353296Z","iopub.status.idle":"2022-11-19T13:32:40.362385Z","shell.execute_reply.started":"2022-11-19T13:32:40.353258Z","shell.execute_reply":"2022-11-19T13:32:40.360285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    #rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ngenerator_main = train_datagen.flow_from_directory(\n    IMAGE_TRAIN,\n    target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\ndef my_generator(generator):\n    while True: # keras requires all generators to be infinite\n        data = next(generator)\n        x = data[0]\n        y = data[1], data[1], data[1]\n        yield x, y\n\ntrain_generator = my_generator(generator_main)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:40.366403Z","iopub.execute_input":"2022-11-19T13:32:40.36785Z","iopub.status.idle":"2022-11-19T13:32:42.154077Z","shell.execute_reply.started":"2022-11-19T13:32:40.367814Z","shell.execute_reply":"2022-11-19T13:32:42.152587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\ndef inception(x, filters):\n    # 1x1\n    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n\n    # 1x1->3x3\n    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n    \n    # 1x1->5x5\n    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n\n    # 3x3->1x1\n    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n\n    return Concatenate(axis=-1)([path1,path2,path3,path4])","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:42.158947Z","iopub.execute_input":"2022-11-19T13:32:42.161026Z","iopub.status.idle":"2022-11-19T13:32:42.173466Z","shell.execute_reply.started":"2022-11-19T13:32:42.160994Z","shell.execute_reply":"2022-11-19T13:32:42.172254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auxiliary(x, name=None):\n    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n    layer = Flatten()(layer)\n    layer = Dense(units=256, activation='relu')(layer)\n    layer = Dropout(0.4)(layer)\n    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n    return layer","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:42.178822Z","iopub.execute_input":"2022-11-19T13:32:42.179418Z","iopub.status.idle":"2022-11-19T13:32:42.192938Z","shell.execute_reply.started":"2022-11-19T13:32:42.179382Z","shell.execute_reply":"2022-11-19T13:32:42.191965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def googlenet():\n    layer_in = Input(shape=IMAGE_SHAPE)\n    \n    # stage-1\n    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n    layer = BatchNormalization()(layer)\n\n    # stage-2\n    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n    layer = BatchNormalization()(layer)\n    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n\n    # stage-3\n    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n    \n    # stage-4\n    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n    aux1  = auxiliary(layer, name='aux1')\n    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n    aux2  = auxiliary(layer, name='aux2')\n    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n    \n    # stage-5\n    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n    \n    # stage-6\n    layer = Flatten()(layer)\n    layer = Dropout(0.4)(layer)\n    layer = Dense(units=256, activation='linear')(layer)\n    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n    \n    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:42.194199Z","iopub.execute_input":"2022-11-19T13:32:42.196111Z","iopub.status.idle":"2022-11-19T13:32:42.224346Z","shell.execute_reply.started":"2022-11-19T13:32:42.196075Z","shell.execute_reply":"2022-11-19T13:32:42.223431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\nmodel = googlenet()\nmodel.summary()\n#model.load_weights(MODEL_NAME)\n#tf.keras.utils.plot_model(model, 'GoogLeNet.png')\n\n#optimizer = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n#optimizer = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n#model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\noptimizer = ['Adam', 'SGD']\nepochs = [20, 30]\nhistory_all = {}\n\nfor i in range(len(optimizer)):\n    print('Usnig optimizer: ' + optimizer[i] + ', Epoch: ' + str(epochs[i]))\n    \n    model.compile(loss='categorical_crossentropy', \n                  loss_weights={'main': 1.0, 'aux1': 0.3, 'aux2': 0.3},\n                  optimizer=optimizer[i], metrics=['accuracy'])\n    \n    train_history = model.fit_generator(\n            train_generator,\n            steps_per_epoch=EPOCH_STEPS,\n            epochs=epochs[i],\n            #callbacks=[checkpoint]\n            shuffle=True\n            )\n    \n    # save history    \n    if len(history_all) == 0:\n        history_all = {key: [] for key in train_history.history}\n    \n    for key in history_all:\n        history_all[key].extend(train_history.history[key])\n\nmodel.save(MODEL_NAME)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-19T13:32:42.229888Z","iopub.execute_input":"2022-11-19T13:32:42.230675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show train history\ndef show_train_history(history, xlabel, ylabel, train):\n    for item in train:\n        plt.plot(history[item])\n    plt.title('Train History')\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.legend(train, loc='upper left')\n    plt.show()\n\nshow_train_history(history_all, 'Epoch', 'Accuracy', ('main_accuracy', 'aux1_accuracy', 'aux2_accuracy'))\nshow_train_history(history_all, 'Epoch', 'Loss', ('main_loss', 'aux1_loss', 'aux2_loss'))","metadata":{"execution":{"iopub.status.busy":"2022-11-19T14:36:24.402253Z","iopub.execute_input":"2022-11-19T14:36:24.402936Z","iopub.status.idle":"2022-11-19T14:36:24.814454Z","shell.execute_reply.started":"2022-11-19T14:36:24.402897Z","shell.execute_reply":"2022-11-19T14:36:24.813587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}